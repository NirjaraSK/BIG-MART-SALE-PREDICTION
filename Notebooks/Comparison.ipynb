{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UQQVf6nek2W",
        "outputId": "fd2dc704-3c2c-488b-9270-e2d1934e78b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM RMSE: 1479.373814401402, Execution Time: 1.9056665897369385 sec\n",
            "Random Forest RMSE: 1081.6580121995075, Execution Time: 2.563660144805908 sec\n",
            "KNN RMSE: 1228.042641296827, Execution Time: 0.01751542091369629 sec\n",
            "XGBoost RMSE: 1132.9234603689106, Execution Time: 0.17472362518310547 sec\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load data (adjust path as needed)\n",
        "big_mart_data = pd.read_csv('/content/drive/MyDrive/archive (3)/Train.csv')\n",
        "\n",
        "# Preprocessing\n",
        "big_mart_data = big_mart_data.select_dtypes(include=[np.number]).dropna()\n",
        "X = big_mart_data.drop(columns=['Item_Outlet_Sales'])  # Features\n",
        "y = big_mart_data['Item_Outlet_Sales']  # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm_model = SVR()\n",
        "start_time = time.time()\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "svm_time = time.time() - start_time\n",
        "svm_rmse = np.sqrt(mean_squared_error(y_test, y_pred_svm))\n",
        "print(f\"SVM RMSE: {svm_rmse}, Execution Time: {svm_time} sec\")\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "rf_time = time.time() - start_time\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "print(f\"Random Forest RMSE: {rf_rmse}, Execution Time: {rf_time} sec\")\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
        "start_time = time.time()\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "knn_time = time.time() - start_time\n",
        "knn_rmse = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
        "print(f\"KNN RMSE: {knn_rmse}, Execution Time: {knn_time} sec\")\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
        "start_time = time.time()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "xgb_time = time.time() - start_time\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "print(f\"XGBoost RMSE: {xgb_rmse}, Execution Time: {xgb_time} sec\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example results dictionary (Replace this with actual results from your model runs)\n",
        "results = {\n",
        "    'SVM': {'RMSE': 1250.5, 'Time': 2.3},\n",
        "    'Random Forest': {'RMSE': 1100.2, 'Time': 4.5},\n",
        "    'KNN': {'RMSE': 1300.8, 'Time': 1.8},\n",
        "    'XGBoost': {'RMSE': 1050.3, 'Time': 3.1}\n",
        "}\n",
        "\n",
        "# Calculate efficiency percentages\n",
        "min_rmse = min([results[model]['RMSE'] for model in results])\n",
        "min_time = min([results[model]['Time'] for model in results])\n",
        "\n",
        "def calculate_efficiency(value, min_value):\n",
        "    return (min_value / value) * 100\n",
        "\n",
        "for model in results:\n",
        "    results[model]['RMSE Efficiency (%)'] = calculate_efficiency(results[model]['RMSE'], min_rmse)\n",
        "    results[model]['Time Efficiency (%)'] = calculate_efficiency(results[model]['Time'], min_time)\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "3ApD0U_UfTVE",
        "outputId": "9438e285-c358-4520-9243-5c8a02443de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 RMSE  Time  RMSE Efficiency (%)  Time Efficiency (%)\n",
            "SVM            1250.5   2.3            83.990404            78.260870\n",
            "Random Forest  1100.2   4.5            95.464461            40.000000\n",
            "KNN            1300.8   1.8            80.742620           100.000000\n",
            "XGBoost        1050.3   3.1           100.000000            58.064516\n"
          ]
        }
      ]
    }
  ]
}